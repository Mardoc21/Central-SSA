{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mardoc21/Central-SSA/blob/main/Gerente_Geral_V53_(Limpeza_Visual).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OUpHlUghjpH",
        "outputId": "50cfce0e-4e21-46f8-f750-4eb015236468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjas2zumhbRL",
        "outputId": "52115d2d-aee5-494b-d92b-a7b575463862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Instalando bibliotecas necessárias...\n",
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Collecting triton>=2 (from openai-whisper)\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2026.1.4)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803980 sha256=844d1ed0cf3e005261b0cd7d4e3d53210a607c1f5853b15395d13a16f1962ad3\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, emoji, colorama, openai-whisper\n",
            "Successfully installed colorama-0.4.6 emoji-2.15.0 openai-whisper-20250625 triton-3.6.0\n",
            "============================================================\n",
            "   GERENTE GERAL V50 (REFINADOR VISUAL)   \n",
            "============================================================\n",
            "[ERRO] Origem não encontrada: /content/drive/MyDrive/MAquina_esteira_d6\n",
            "Processamento concluído. O DataFrame está disponível como 'df_relatorio'.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Install missing libraries if not already installed\n",
        "try:\n",
        "    import whisper\n",
        "except ImportError:\n",
        "    print(\"Instalando bibliotecas necessárias...\")\n",
        "    !pip install openai-whisper torch tqdm colorama pandas openpyxl emoji\n",
        "    import whisper # Try importing again after installation\n",
        "\n",
        "from tqdm import tqdm\n",
        "import emoji\n",
        "from colorama import Fore, init\n",
        "\n",
        "init(autoreset=True)\n",
        "\n",
        "# --- CONFIGURAÇÕES ---\n",
        "USER_HOME = Path.home()\n",
        "# Caminho atualizado conforme solicitação do usuário\n",
        "PASTA_DOWNLOADS = Path('/content/drive/MyDrive/MAquina_esteira_d6')\n",
        "PASTA_DESTINO = Path.cwd() / \"Conversas_Tabuladas_V50\"\n",
        "MODELO_IA = \"base\"\n",
        "\n",
        "# --- FUNÇÕES DE LIMPEZA AVANÇADA ---\n",
        "\n",
        "def limpar_texto_conteudo(texto):\n",
        "    if not isinstance(texto, str): return \"\"\n",
        "    # Remove caracteres de formatação do WhatsApp (LTR/RTL marks)\n",
        "    texto = texto.replace('\\u200e', '').replace('\\u202c', '').replace('\\u202a', '')\n",
        "    return texto.strip()\n",
        "\n",
        "def limpar_nome_grupo_refinado(nome_arquivo):\n",
        "    # 1. Limpeza básica do arquivo zip\n",
        "    nome = re.sub(r'\\s\\(\\d+\\)$', '', nome_arquivo)\n",
        "    if nome.lower().endswith('.zip'): nome = nome[:-4]\n",
        "\n",
        "    # 2. Remove \"Conversa do WhatsApp com\"\n",
        "    match = re.search(r' com (.*)', nome, re.IGNORECASE)\n",
        "    if match: nome = match.group(1).strip()\n",
        "\n",
        "    # 3. Remove palavra \"OBRAS\" (solicitação específica)\n",
        "    nome = re.sub(r'\\bobras\\b', '', nome, flags=re.IGNORECASE)\n",
        "\n",
        "    # 4. Remove Emojis do nome do grupo\n",
        "    nome = emoji.replace_emoji(nome, replace='')\n",
        "\n",
        "    # 5. Remove espaços duplos e traços soltos\n",
        "    nome = re.sub(r'\\s+', ' ', nome).strip()\n",
        "    nome = nome.strip('-').strip()\n",
        "\n",
        "    return nome\n",
        "\n",
        "def obter_primeiro_nome(nome_completo):\n",
        "    # Remove emojis do nome da pessoa\n",
        "    nome_limpo = emoji.replace_emoji(nome_completo, replace='')\n",
        "    # Pega só o primeiro nome (separado por espaço)\n",
        "    partes = nome_limpo.split()\n",
        "    if partes:\n",
        "        return partes[0].title() # Capitaliza (Rafael)\n",
        "    return nome_limpo\n",
        "\n",
        "def carregar_memoria(pasta):\n",
        "    arq = pasta / 'memoria_transcricoes.json'\n",
        "    if arq.exists():\n",
        "        try: return json.load(open(arq, encoding='utf-8'))\n",
        "        except: return {}\n",
        "    return {}\n",
        "\n",
        "def salvar_memoria(pasta, dados):\n",
        "    json.dump(dados, open(pasta / 'memoria_transcricoes.json', 'w', encoding='utf-8'), indent=4, ensure_ascii=False)\n",
        "\n",
        "def parse_linha_whatsapp(linha):\n",
        "    # Regex ajustado para capturar mensagens\n",
        "    padrao = r'^(\\d{2}/\\d{2}/\\d{4})\\s+(\\d{2}:\\d{2})\\s+-\\s+([^:]+):\\s+(.*)'\n",
        "    match = re.search(padrao, linha)\n",
        "\n",
        "    if match:\n",
        "        return {\n",
        "            'data': match.group(1),\n",
        "            'hora': match.group(2),\n",
        "            'autor': limpar_texto_conteudo(match.group(3)),\n",
        "            'msg': limpar_texto_conteudo(match.group(4)),\n",
        "            'raw': linha\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# --- MAIN --- (Refatorada para retornar DataFrame)\n",
        "\n",
        "def main_process_whatsapp():\n",
        "    print(f\"{Fore.CYAN}{'='*60}\")\n",
        "    print(f\"{Fore.WHITE}   GERENTE GERAL V50 (REFINADOR VISUAL)   \")\n",
        "    print(f\"{Fore.CYAN}{'='*60}\")\n",
        "\n",
        "    if not PASTA_DOWNLOADS.exists():\n",
        "        print(f\"{Fore.RED}[ERRO] Origem não encontrada: {PASTA_DOWNLOADS}\")\n",
        "        return pd.DataFrame() # Retorna DataFrame vazio em caso de erro\n",
        "\n",
        "    PASTA_DESTINO.mkdir(exist_ok=True)\n",
        "\n",
        "    # CORREÇÃO: Busca arquivos 'Conversa*' e valida se são ZIPs, independente da extensão\n",
        "    todos_arquivos = list(PASTA_DOWNLOADS.glob(\"Conversa*\"))\n",
        "    zips = [f for f in todos_arquivos if zipfile.is_zipfile(f)]\n",
        "\n",
        "    # Ordena por data de modificação\n",
        "    zips.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "\n",
        "    print(f\"Arquivos ZIP detectados: {len(zips)}\")\n",
        "\n",
        "    print(f\"Carregando IA ({MODELO_IA})...\")\n",
        "    try:\n",
        "        model = whisper.load_model(MODELO_IA)\n",
        "    except Exception as e:\n",
        "        print(f\"{Fore.RED}Erro ao carregar IA: {e}\")\n",
        "        return pd.DataFrame() # Retorna DataFrame vazio em caso de erro\n",
        "\n",
        "    dados_tabela = []\n",
        "\n",
        "    for zip_path in tqdm(zips, unit=\"zip\", desc=\"Processando\"):\n",
        "        # Aplica a limpeza refinada no nome do grupo (Sem \"Obras\", sem Emojis)\n",
        "        nome_grupo_final = limpar_nome_grupo_refinado(zip_path.name)\n",
        "\n",
        "        # Pasta temporária para extração\n",
        "        pasta_temp = PASTA_DESTINO / \"temp\" / f\"temp_{int(datetime.now().timestamp())}\"\n",
        "\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "                pasta_temp.mkdir(parents=True, exist_ok=True)\n",
        "                zf.extractall(pasta_temp)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        txt_file = list(pasta_temp.glob(\"*.txt\"))\n",
        "        if not txt_file:\n",
        "            shutil.rmtree(pasta_temp, ignore_errors=True)\n",
        "            continue\n",
        "\n",
        "        # Usa memória global para não reprocessar áudios repetidos em grupos diferentes\n",
        "        memoria_path = PASTA_DESTINO / \"memoria_geral.json\"\n",
        "        if memoria_path.exists():\n",
        "            memoria = json.load(open(memoria_path, encoding='utf-8'))\n",
        "        else:\n",
        "            memoria = {}\n",
        "\n",
        "        try:\n",
        "            lines = open(txt_file[0], 'r', encoding='utf-8').readlines()\n",
        "        except:\n",
        "            try:\n",
        "                lines = open(txt_file[0], 'r', encoding='latin-1').readlines()\n",
        "            except:\n",
        "                lines = []\n",
        "\n",
        "        houve_transcricao = False\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line: continue\n",
        "\n",
        "            parsed = parse_linha_whatsapp(line)\n",
        "\n",
        "            if parsed:\n",
        "                # 1. Aplica limpeza no nome do autor (Primeiro Nome)\n",
        "                autor_curto = obter_primeiro_nome(parsed['autor'])\n",
        "\n",
        "                # 2. Ignora mensagens de sistema\n",
        "                if \"As mensagens e as chamadas são protegidas\" in parsed['msg']: continue\n",
        "\n",
        "                conteudo_final = parsed['msg']\n",
        "                tipo_msg = \"Texto\"\n",
        "                arquivo_nome = \"\"\n",
        "\n",
        "                # Verifica Mídia\n",
        "                match_media = re.search(r'([\\w-]+\\.(opus|ogg|mp3|m4a|wav|jpg|mp4)) \\(arquivo anexado\\)', parsed['raw'], re.IGNORECASE)\n",
        "\n",
        "                if match_media:\n",
        "                    nome_arquivo = match_media.group(1)\n",
        "                    extensao = match_media.group(2).lower()\n",
        "                    arquivo_nome = nome_arquivo\n",
        "\n",
        "                    if extensao in ['opus', 'ogg', 'mp3', 'm4a', 'wav']:\n",
        "                        tipo_msg = \"Áudio\"\n",
        "                        caminho_fisico = pasta_temp / nome_arquivo\n",
        "\n",
        "                        if nome_arquivo in memoria:\n",
        "                            conteudo_final = f\"[ÁUDIO]: {memoria[nome_arquivo]}\"\n",
        "                        elif caminho_fisico.exists():\n",
        "                            try:\n",
        "                                res = model.transcribe(str(caminho_fisico))\n",
        "                                texto_ia = res['text'].strip()\n",
        "                                memoria[nome_arquivo] = texto_ia\n",
        "                                conteudo_final = f\"[ÁUDIO]: {texto_ia}\"\n",
        "                                houve_transcricao = True\n",
        "                            except Exception as e:\n",
        "                                conteudo_final = f\"[Erro na Transcrição: {e}]\"\n",
        "                        else:\n",
        "                            conteudo_final = \"[Áudio não baixado]\"\n",
        "\n",
        "                    elif extensao in ['jpg', 'mp4']:\n",
        "                        tipo_msg = \"Mídia Visual\"\n",
        "                        conteudo_final = f\"[Arquivo: {nome_arquivo}]\"\n",
        "\n",
        "                # Adiciona à tabela com os campos limpos\n",
        "                dados_tabela.append({\n",
        "                    'Grupo': nome_grupo_final,\n",
        "                    'Data': parsed['data'],\n",
        "                    'Hora': parsed['hora'],\n",
        "                    'Autor': autor_curto,\n",
        "                    'Conteúdo': conteudo_final,\n",
        "                    'Tipo': tipo_msg,\n",
        "                    'Arquivo Original': arquivo_nome\n",
        "                })\n",
        "\n",
        "            else:\n",
        "                # Continuação de mensagem (multilinha)\n",
        "                if dados_tabela:\n",
        "                    # Adiciona quebra de linha real para o Excel\n",
        "                    dados_tabela[-1]['Conteúdo'] += f\"\\n{limpar_texto_conteudo(line)}\"\n",
        "\n",
        "        shutil.rmtree(pasta_temp, ignore_errors=True)\n",
        "\n",
        "        if houve_transcricao:\n",
        "            json.dump(memoria, open(memoria_path, 'w', encoding='utf-8'), indent=4, ensure_ascii=False)\n",
        "\n",
        "    # --- PREPARAR DATAFRAME ---\n",
        "    print(f\"\\n{Fore.GREEN}Preparando DataFrame Limpo...\")\n",
        "\n",
        "    if dados_tabela:\n",
        "        df = pd.DataFrame(dados_tabela)\n",
        "\n",
        "        # Ordenação Cronológica Reversa\n",
        "        df['Data_Iso'] = pd.to_datetime(df['Data'], format='%d/%m/%Y', errors='coerce')\n",
        "        df = df.sort_values(by=['Data_Iso', 'Hora'], ascending=[False, False])\n",
        "        df = df.drop(columns=['Data_Iso'])\n",
        "\n",
        "        print(\"DataFrame processado com sucesso.\")\n",
        "        return df\n",
        "    else:\n",
        "        print(\"Nenhum dado encontrado.\")\n",
        "        return pd.DataFrame() # Retorna um DataFrame vazio se não houver dados\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df_relatorio = main_process_whatsapp()\n",
        "    print(\"Processamento concluído. O DataFrame está disponível como 'df_relatorio'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb808cbf"
      },
      "outputs": [],
      "source": [
        "if 'df_relatorio' in locals() and isinstance(df_relatorio, pd.DataFrame) and not df_relatorio.empty:\n",
        "    print(f\"Total de mensagens processadas: {len(df_relatorio)}\")\n",
        "    print(\"\\n--- Primeiras 5 linhas ---\")\n",
        "    display(df_relatorio.head())\n",
        "    print(\"\\n--- Estrutura do DataFrame ---\")\n",
        "    df_relatorio.info()\n",
        "else:\n",
        "    print(\"O DataFrame 'df_relatorio' ainda não está disponível ou está vazio.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df17d324"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PASTA_DOWNLOADS = Path('/content/drive/MyDrive/1A/Histórico backup conversas')\n",
        "print(f\"Diagnóstico detalhado em: {PASTA_DOWNLOADS}\\n\")\n",
        "\n",
        "if PASTA_DOWNLOADS.exists():\n",
        "    arquivos = list(PASTA_DOWNLOADS.iterdir())\n",
        "\n",
        "    for arq in arquivos:\n",
        "        if arq.is_dir(): continue\n",
        "\n",
        "        print(f\"Analisando: {arq.name}\")\n",
        "\n",
        "        # Verifica se é um zip válido, independente da extensão\n",
        "        if zipfile.is_zipfile(arq):\n",
        "            print(f\"  [VALIDADO] É um arquivo ZIP válido.\")\n",
        "            try:\n",
        "                with zipfile.ZipFile(arq, 'r') as zf:\n",
        "                    arquivos_internos = zf.namelist()\n",
        "                    txts = [f for f in arquivos_internos if f.lower().endswith('.txt')]\n",
        "\n",
        "                    print(f\"  Conteúdo ({len(arquivos_internos)} itens):\")\n",
        "                    for f in arquivos_internos[:5]: # Lista os 5 primeiros\n",
        "                        print(f\"    - {f}\")\n",
        "                    if len(arquivos_internos) > 5: print(\"    ...\")\n",
        "\n",
        "                    if txts:\n",
        "                        print(f\"  --> Arquivo de texto encontrado: {txts}\")\n",
        "                    else:\n",
        "                        print(f\"  [ALERTA] NENHUM arquivo .txt encontrado na raiz do zip.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  [ERRO] Falha ao ler zip: {e}\")\n",
        "        else:\n",
        "            print(f\"  [X] NÃO é um arquivo ZIP.\")\n",
        "        print(\"-\"*40)\n",
        "else:\n",
        "    print(\"Pasta não encontrada.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f456758"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "PASTA_DESTINO = Path.cwd() / \"Conversas_Tabuladas_V50\"\n",
        "csv_path = PASTA_DESTINO / \"Relatorio_Refinado_V50.csv\"\n",
        "\n",
        "try:\n",
        "    df_relatorio = pd.read_csv(csv_path, sep=';', encoding='utf-8-sig')\n",
        "    print(f\"Arquivo '{csv_path.name}' carregado com sucesso!\")\n",
        "    display(df_relatorio.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"[ERRO] O arquivo '{csv_path.name}' não foi encontrado em '{csv_path}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERRO] Ocorreu um erro ao carregar o arquivo: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ac53b9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PASTA_DOWNLOADS = Path('/content/drive/MyDrive/VGP_SISTEMA/01_Inbox_WhatsApp')\n",
        "\n",
        "print(f\"Verificando a pasta: {PASTA_DOWNLOADS}\")\n",
        "\n",
        "if not PASTA_DOWNLOADS.exists():\n",
        "    print(f\"[ERRO] A pasta '{PASTA_DOWNLOADS}' N\\u00c3O foi encontrada.\")\n",
        "elif not PASTA_DOWNLOADS.is_dir():\n",
        "    print(f\"[ERRO] '{PASTA_DOWNLOADS}' N\\u00c3O \\u00e9 um diret\\u00f3rio.\")\n",
        "else:\n",
        "    zip_files = list(PASTA_DOWNLOADS.glob(\"*.zip\"))\n",
        "    if zip_files:\n",
        "        print(f\"Arquivos .zip encontrados na pasta '{PASTA_DOWNLOADS}':\")\n",
        "        for f in zip_files:\n",
        "            print(f\"- {f.name}\")\n",
        "    else:\n",
        "        print(f\"Nenhum arquivo .zip encontrado na pasta '{PASTA_DOWNLOADS}'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cf901d2"
      },
      "source": [
        "# Task\n",
        "Check the structure of the `df_relatorio` DataFrame by displaying its first few rows, checking data types, and summarizing the columns to understand the available data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aae9ed3"
      },
      "source": [
        "## Data Inspection\n",
        "\n",
        "### Subtask:\n",
        "Inspect the `df_relatorio` DataFrame to understand its structure, column types, and content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52ed466b"
      },
      "source": [
        "**Reasoning**:\n",
        "I will generate a code block to inspect the `df_relatorio` DataFrame. This block will verify if the DataFrame exists in the current session, and if so, it will print its shape, display the first 5 rows, and show the dataframe summary information, satisfying the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5660cedc"
      },
      "outputs": [],
      "source": [
        "if 'df_relatorio' in locals() and isinstance(df_relatorio, pd.DataFrame):\n",
        "    print(f\"DataFrame Shape: {df_relatorio.shape}\")\n",
        "    print(\"\\n--- First 5 rows ---\")\n",
        "    display(df_relatorio.head())\n",
        "    print(\"\\n--- DataFrame Info ---\")\n",
        "    df_relatorio.info()\n",
        "else:\n",
        "    print(\"The DataFrame 'df_relatorio' is not available. Please ensure the processing step was executed successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}